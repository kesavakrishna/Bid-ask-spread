{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kesavakrishna/Bid-ask-spread/blob/main/Bibliometric%20Analysis/code/Bibliographic_Coupling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcAinVjsI9zw",
        "outputId": "f4f9a5f0-20ff-4ffe-e187-0c9c12d7b0f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 Pairs of References by Bibliometric Coupling:\n",
            "                                             References  Coupling Count\n",
            "420   (Abdi, F., Ranaldo, A., A simple estimation of...              70\n",
            "1226  (Aitken, M., Frino, A., Execution costs associ...              67\n",
            "974   (Agarwal, P., Oâ€™Hara, M., (2006), Information ...              66\n",
            "440   (Akerlof, G., The market for \"lemons\": quality...              48\n",
            "1031  (Amihud, Y., Mendelson, H., Dealership market:...              40\n",
            "357   (Abeysekera, A.P., Nimal, P.D., The four-facto...              38\n",
            "1281  (Amihud, Y., Illiquidity and stock returns: Cr...              37\n",
            "1066  (Acharya, V.V., Pedersen, H., Asset pricing wi...              28\n",
            "1618  (Bhattacharya, M., Transaction data tests of e...              26\n",
            "687   (Abdi, F., Ranaldo, A., A simple estimation of...              25\n",
            "585   (Qiu, T., Chen, G., Zhong, L.X., Wu, X.R., Dyn...              24\n",
            "1313  (Anand, A., Karagozoglu, A., Relative performa...              20\n",
            "726   (Bao, J., Pan, J., Wang, J., The illiquidity o...              18\n",
            "2105  (Amihud, Haim, Trading mechanisms and stock re...              17\n",
            "1711  (Affleck-Graves, J., Hedge, S., Miller, R., Tr...              16\n",
            "1033  (Aitken, M., Frino, A., Execution costs associ...              14\n",
            "1951  (Amihud, Y., Mendelson, H., Trading mechanisms...              12\n",
            "692   (Abdi, F., Ranaldo, A., A simple estimation of...              12\n",
            "426   (Abdi, F., Ranaldo, A., A simple estimation of...               7\n",
            "53    (Abdi, F., Ranaldo, A., A simple estimation of...               5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load input paper data from two datasets into pandas DataFrames\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/scopus 112_new.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/scopus 21bid_ask.csv')\n",
        "\n",
        "# Extract references from each paper in the datasets\n",
        "references1 = df1['References'].tolist()  # Assuming the references are stored in a column named 'References' in the DataFrame\n",
        "references2 = df2['References'].tolist()\n",
        "\n",
        "# Create a dictionary to store bibliometric coupling counts\n",
        "bibliometric_coupling = defaultdict(int)\n",
        "\n",
        "# Iterate through all combinations of references from the two datasets\n",
        "for ref1 in references1:\n",
        "    for ref2 in references2:\n",
        "        # Split the references into sets and calculate the number of common references\n",
        "        set1 = set(ref1.split(';')) if pd.notna(ref1) else set()\n",
        "        set2 = set(ref2.split(';')) if pd.notna(ref2) else set()\n",
        "        common_references = set1.intersection(set2)\n",
        "        coupling_count = len(common_references)\n",
        "\n",
        "        # Add the coupling count to the dictionary with a tuple key\n",
        "        key = tuple(sorted([ref1, ref2]))\n",
        "        bibliometric_coupling[key] += coupling_count\n",
        "\n",
        "# Convert the bibliometric coupling dictionary to a DataFrame\n",
        "bibliometric_coupling_df = pd.DataFrame(list(bibliometric_coupling.items()), columns=['References', 'Coupling Count'])\n",
        "\n",
        "# Sort the DataFrame by coupling count in descending order\n",
        "bibliometric_coupling_df = bibliometric_coupling_df.sort_values(by='Coupling Count', ascending=False)\n",
        "\n",
        "# Display the top N pairs with the highest coupling count\n",
        "N = 20  # Change N to the desired number of pairs to display\n",
        "top_couples = bibliometric_coupling_df.head(N)\n",
        "print(f'Top {N} Pairs of References by Bibliometric Coupling:')\n",
        "print(top_couples)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETouqU-VJG1j",
        "outputId": "9519ba46-ba57-4ef2-f5e5-97f7c3201f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}